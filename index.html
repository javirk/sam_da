<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="SAM-DA: Decoder Adapter for Efficient Medical Domain Adaptation">
  <meta name="keywords" content="SAM-DA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SAM-DA: Decoder Adapter for Efficient Medical Domain Adaptation</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
  MathJax = {
    tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
  };
  </script>
</head>
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SAM-DA: Decoder Adapter for Efficient Medical Domain Adaptation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.javiergamazo.com">Javier Gamazo Tejero</a><sup>1</sup>,
            </span>
            <span class="author-block">
              Moritz Schmid<sup>1</sup>,
            </span>
            <span class="author-block">
              Pablo MÃ¡rquez Neila<sup>1</sup>,
            </span>
            <span class="author-block">
              Martin Zinkernagel<sup>2</sup>,
            </span>
            <span class="author-block">
              Sebastian Wolf<sup>2</sup>,
            </span>
            <span class="author-block">
              Raphael Sznitman<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Bern,</span>
            <span class="author-block"><sup>2</sup>Inselspital Bern</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2303.11678.pdf"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2303.11678"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=RIdJbANtMAs&ab_channel=JavierGamazoTejero"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Main figure -->
    <div class="columns is-centered has-text-centered">
      <img src = "./static/images/method.svg" alt="Method"/>
    </div>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper addresses the domain adaptation challenge for semantic segmentation in medical imaging. 
            Despite the impressive performance of recent foundational segmentation models like SAM on natural images, 
            they struggle with medical domain images. Beyond this, recent approaches that perform end-to-end fine-tuning of models 
            are simply not computationally tractable. To address this, we propose a novel SAM adapter approach that minimizes the number 
            of trainable parameters while achieving comparable performances to full fine-tuning. The proposed SAM adapter is 
            strategically placed in the mask decoder, offering excellent and broad generalization capabilities and improved 
            segmentation across both fully supervised and test-time domain adaptation tasks. Extensive validation on four datasets 
            showcases the adapter's efficacy, outperforming existing methods while training less than 1% of SAM's total parameters.  
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/PixUJ9Xl5_8?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Main method. -->
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3">Method</h2>
        <!-- Another title. -->
        <p>
          We introduce a new learnable adaptation prompt $A_\ell\in\mathbb{R}^{N\times{}D}$ at each layer $\ell$ of the mask decoder's transformer. 
          The adaptation prompts are used to compute correction factors that modify the embeddings of the transformer without retraining its parameters. 
          Formally, let $T_\ell\in\mathbb{R}^{M\times D}$ be the embeddings obtained as the output of the cross-attention operation at layer $\ell$.
          Then, we feed $A_\ell$ and $T_\ell$ to an additional attention block, where the embeddings $T_\ell$ act as queries and the adapter weights $A_\ell$ act as keys and values. 
          The attention scores $S_\ell$ are calculated as usual and projected back to the model dimension $D$ with a linear layer, $S'_\ell=\text{Linear}^o_\ell(S_\ell)$. The result $S'_\ell$ serves as the correction factor of the original embeddings,
        </p>

        <p>
          \[ T'_\ell = \text{Linear}^t_\ell(T_\ell + g_\ell \cdot S'_\ell) \]

        </p>
        <p>
          where the learnable gating factor~$g_\ell\in\mathbb{R}$ is initialized to0 to ensure no disruption during the early stages of adaptation learning.
        </p>
        <br/>
        <!--/ Another title. -->
      </div>
    </div>
    <!--/ Main method. -->

    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Results</h2>
        <p class="has-text-justified"> 
          We evaluate our method on four datasets. Three of them are medical datasets and one is a natural image dataset. We evaluate our method in three scenarios: full supervision, domain generalization and test-time domain adaptation. For exact numbers, please refer to the paper linked above.
        </p>  
        <h4 class="title is-4" style="margin-top: 20px;">Full Supervision</h4>
        <div class="content has-text-justified">
          <img src = "./static/images/full_supervision.webp" alt="Full Supervision"/>
        </div>
        <h4 class="title is-4" style="margin-top: 20px;">Domain Generalization</h4>
        <div class="content has-text-justified">
          <img src = "./static/images/generalization.webp" alt="Full Supervision"/>
        </div>
        <h4 class="title is-4" style="margin-top: 20px;">Test-time Domain Adaptation</h4>
        <div class="content has-text-justified">
          <img src = "./static/images/ttda.webp" alt="Full Supervision"/>
        </div>
      </div>
    </div>
    <!--/ Results. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{tejero2025samda,
  title={SAM-DA: Decoder Adapter for Efficient Medical Domain Adaptation },
  author={Gamazo Tejero, Javier and Schmid, Moritz and M{\'a}rquez Neila, Pablo and Zinkernagel, Martin S and Wolf, Sebastian and Sznitman, Raphael },
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2303.11678.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/javirk" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a> and has been adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
